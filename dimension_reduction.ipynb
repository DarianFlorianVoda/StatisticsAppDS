{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the MNIST dataset\n",
    "http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 14s 1us/step\n",
      "train_X: (60000, 28, 28) → type: <class 'numpy.ndarray'>\n",
      "train_y: (60000,) → type: <class 'numpy.ndarray'>\n",
      "test_X: (10000, 28, 28) → type: <class 'numpy.ndarray'>\n",
      "test_y: (10000,) → type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "print(f'train_X: {train_X.shape} → type: {type(train_X)}')\n",
    "print(f'train_y: {train_y.shape} → type: {type(train_y)}')\n",
    "print(f'test_X: {test_X.shape} → type: {type(test_X)}')\n",
    "print(f'test_y: {test_y.shape} → type: {type(test_y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten each array to a 28x28 = 784 dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x: (60000, 784)\n",
      "test_x: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_X = train_X.reshape(train_X.shape[0], -1)\n",
    "test_X = test_X.reshape(test_X.shape[0], -1)\n",
    "\n",
    "print(f'train_x: {train_X.shape}')\n",
    "print(f'test_x: {test_X.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale images from the range of [0,255] to the range of [0.0,1.0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_scale: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "test_x_scale: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_X_scale = minmax_scale.fit_transform(train_X)\n",
    "\n",
    "test_x_scale = minmax_scale.fit_transform(test_X)\n",
    "\n",
    "print(f'train_x_scale: {train_X_scale}')\n",
    "print(f'test_x_scale: {test_x_scale}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot first 9 entries in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_6976\\2541685302.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m         \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maxes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mj\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_X\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m28\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m28\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt.axes[i, j].imshow(train_X.reshape(28, 28))\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(test_x_scale[:10])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to Pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data\n",
    "df_train = pd.DataFrame(train_X_scale)\n",
    "df_test = pd.DataFrame(test_x_scale)\n",
    "\n",
    "y_train = pd.DataFrame(train_y)\n",
    "y_test = pd.DataFrame(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([9.70429203e-02, 7.09565194e-02, 6.16885230e-02, 5.38921329e-02,\n       4.86861032e-02, 4.31206600e-02, 3.27180453e-02, 2.88378525e-02,\n       2.76192360e-02, 2.35691020e-02, 2.10910875e-02, 2.02291363e-02,\n       1.71575259e-02, 1.69204675e-02, 1.57858079e-02, 1.48289613e-02,\n       1.32451022e-02, 1.27684890e-02, 1.18721751e-02, 1.15263966e-02,\n       1.06612548e-02, 1.00667499e-02, 9.53537139e-03, 9.12508969e-03,\n       8.83370961e-03, 8.39287108e-03, 8.12547818e-03, 7.86336079e-03,\n       7.44704697e-03, 6.90832834e-03, 6.58068792e-03, 6.48123181e-03,\n       6.02592027e-03, 5.86559959e-03, 5.69999705e-03, 5.43607094e-03,\n       5.05767086e-03, 4.87840166e-03, 4.81411135e-03, 4.72248386e-03,\n       4.56729640e-03, 4.44819125e-03, 4.18485442e-03, 3.98200212e-03,\n       3.84959984e-03, 3.75089082e-03, 3.61995122e-03, 3.51578010e-03,\n       3.40045393e-03, 3.21862442e-03, 3.19005004e-03, 3.12793074e-03,\n       2.95971452e-03, 2.88943728e-03, 2.84119693e-03, 2.71425678e-03,\n       2.69511197e-03, 2.58462776e-03, 2.53761153e-03, 2.44771804e-03,\n       2.40497153e-03, 2.39253820e-03, 2.30399819e-03, 2.21523734e-03,\n       2.13712840e-03, 2.07217410e-03, 2.03035015e-03, 1.96775178e-03,\n       1.92845406e-03, 1.88625350e-03, 1.86970070e-03, 1.81076220e-03,\n       1.77555496e-03, 1.74891510e-03, 1.65752098e-03, 1.63887815e-03,\n       1.61456298e-03, 1.55110594e-03, 1.47607443e-03, 1.43170716e-03,\n       1.42089007e-03, 1.41148060e-03, 1.40169520e-03, 1.35731301e-03,\n       1.33842136e-03, 1.32391371e-03, 1.30152435e-03, 1.25868497e-03,\n       1.22823571e-03, 1.21579976e-03, 1.17030094e-03, 1.14869344e-03,\n       1.13240004e-03, 1.10881502e-03, 1.08997806e-03, 1.06919354e-03,\n       1.04192138e-03, 1.04003014e-03, 1.01252592e-03, 1.00523535e-03,\n       9.83981763e-04, 9.49651387e-04, 9.41307340e-04, 9.16133395e-04,\n       9.07817013e-04, 8.96840796e-04, 8.65359124e-04, 8.55141833e-04,\n       8.45588978e-04, 8.22467574e-04, 7.91556446e-04, 7.85911342e-04,\n       7.84579503e-04, 7.68804587e-04, 7.63988833e-04, 7.53061049e-04,\n       7.36756509e-04, 7.27105852e-04, 7.19625664e-04, 7.06792253e-04,\n       6.95400134e-04, 6.92135797e-04, 6.83278742e-04, 6.74037192e-04,\n       6.66852855e-04, 6.45242858e-04, 6.35571593e-04, 6.31624049e-04,\n       6.22911700e-04, 6.05268477e-04, 6.03567548e-04, 5.94459751e-04,\n       5.88288592e-04, 5.86499400e-04, 5.81319981e-04, 5.76810337e-04,\n       5.65349445e-04, 5.54744449e-04, 5.35151698e-04, 5.25907104e-04,\n       5.25074693e-04, 5.10239520e-04, 5.02953398e-04, 5.01062377e-04,\n       4.98696439e-04, 4.91052921e-04, 4.85521300e-04, 4.82829877e-04,\n       4.73999105e-04, 4.68336443e-04, 4.66582844e-04, 4.63312037e-04,\n       4.59278255e-04, 4.50364240e-04, 4.48791347e-04, 4.42694603e-04,\n       4.36659935e-04, 4.27435111e-04, 4.24966304e-04, 4.21997998e-04,\n       4.15498996e-04, 4.09622806e-04, 4.00809944e-04, 3.97868809e-04,\n       3.94066898e-04, 3.90480583e-04, 3.85840245e-04, 3.79764317e-04,\n       3.78886809e-04, 3.73926802e-04, 3.69402555e-04, 3.65140766e-04,\n       3.63801539e-04, 3.59862047e-04, 3.54632140e-04, 3.52885989e-04,\n       3.47277011e-04, 3.45946266e-04, 3.41437646e-04, 3.37635803e-04,\n       3.37083217e-04, 3.30216220e-04, 3.28344751e-04, 3.25897023e-04,\n       3.22933686e-04, 3.21259539e-04, 3.17289522e-04, 3.16164779e-04,\n       3.10932096e-04, 3.09527566e-04, 3.05958927e-04, 3.03265000e-04,\n       3.02400330e-04, 3.01559199e-04, 2.96698215e-04, 2.95736601e-04,\n       2.93462927e-04, 2.92663301e-04, 2.87742658e-04, 2.84336790e-04,\n       2.81958073e-04, 2.79061594e-04, 2.75725634e-04, 2.72466224e-04,\n       2.69426649e-04, 2.67698755e-04, 2.65112173e-04, 2.64318603e-04,\n       2.61875107e-04, 2.59445367e-04, 2.58549431e-04, 2.56914449e-04,\n       2.54729132e-04, 2.52803592e-04, 2.52281905e-04, 2.49557031e-04,\n       2.48510936e-04, 2.46068272e-04, 2.43949604e-04, 2.41855647e-04,\n       2.40960275e-04, 2.40435983e-04, 2.38261755e-04, 2.36845943e-04,\n       2.32570235e-04, 2.31301717e-04, 2.30120836e-04, 2.28080341e-04,\n       2.27577444e-04, 2.22769488e-04, 2.21857004e-04, 2.20436846e-04,\n       2.17861568e-04, 2.16652152e-04, 2.15157527e-04, 2.14188091e-04,\n       2.12848873e-04, 2.10367583e-04, 2.09748814e-04, 2.06954716e-04,\n       2.04718668e-04, 2.04264817e-04, 2.01308627e-04, 2.00979201e-04,\n       1.98992260e-04, 1.97624842e-04, 1.95823763e-04, 1.93723425e-04,\n       1.92853827e-04, 1.91766955e-04, 1.91537901e-04, 1.89075053e-04,\n       1.88007349e-04, 1.86387898e-04, 1.85843669e-04, 1.84613660e-04,\n       1.83691277e-04, 1.83143588e-04, 1.81877299e-04, 1.79861984e-04,\n       1.77551631e-04, 1.76684986e-04, 1.75957994e-04, 1.73879794e-04,\n       1.73424712e-04, 1.72640963e-04, 1.71381662e-04, 1.70032390e-04,\n       1.69298957e-04, 1.68004785e-04, 1.66919942e-04, 1.66448520e-04,\n       1.64202255e-04, 1.63478209e-04, 1.62654036e-04, 1.61886197e-04,\n       1.60888909e-04, 1.59842423e-04, 1.58828424e-04, 1.57349163e-04,\n       1.56734388e-04, 1.54893119e-04, 1.53806308e-04, 1.53064803e-04,\n       1.52035526e-04, 1.50007181e-04, 1.49662433e-04, 1.48226488e-04,\n       1.47670461e-04, 1.46124322e-04, 1.44649150e-04, 1.43230635e-04,\n       1.42720376e-04, 1.42065828e-04, 1.41746283e-04, 1.40489235e-04,\n       1.38235388e-04, 1.37968808e-04, 1.36837631e-04, 1.35973201e-04,\n       1.35792940e-04, 1.34506729e-04, 1.33614292e-04, 1.32340586e-04,\n       1.30699779e-04, 1.30188521e-04, 1.29161168e-04, 1.28114790e-04,\n       1.27513317e-04, 1.27215536e-04, 1.26336252e-04, 1.25857238e-04,\n       1.24729822e-04, 1.23559402e-04, 1.22621826e-04, 1.21567356e-04,\n       1.21025541e-04, 1.19966034e-04, 1.19419863e-04, 1.18946487e-04,\n       1.17871678e-04, 1.17058581e-04, 1.16494417e-04, 1.16098690e-04,\n       1.14528999e-04, 1.14215557e-04, 1.12404280e-04, 1.11274530e-04,\n       1.10537446e-04, 1.10431416e-04, 1.10056555e-04, 1.08974768e-04,\n       1.08321015e-04, 1.07594761e-04, 1.07004125e-04, 1.06203776e-04,\n       1.05927243e-04, 1.05049092e-04, 1.03419585e-04, 1.02249361e-04,\n       1.02045301e-04, 1.00845807e-04, 1.00262639e-04, 9.95979352e-05,\n       9.93711977e-05, 9.81238213e-05, 9.75957213e-05, 9.68299214e-05,\n       9.55264376e-05, 9.45437180e-05, 9.37973211e-05, 9.37210577e-05,\n       9.24922830e-05, 9.15858706e-05, 9.13960655e-05, 9.06743465e-05,\n       9.00744778e-05, 8.93696601e-05, 8.91546085e-05, 8.82615693e-05,\n       8.73272285e-05, 8.63121243e-05, 8.55747985e-05, 8.51580336e-05,\n       8.46001730e-05, 8.33126598e-05, 8.29836817e-05, 8.24995197e-05,\n       8.19126471e-05, 8.10910288e-05, 8.09047810e-05, 7.96143261e-05,\n       7.94679162e-05, 7.86272015e-05, 7.80644064e-05, 7.74268204e-05,\n       7.65903822e-05, 7.58098619e-05, 7.46281627e-05, 7.38470870e-05,\n       7.35726010e-05, 7.28175645e-05, 7.27148567e-05, 7.20686658e-05,\n       7.14199574e-05, 7.08076956e-05, 6.96601794e-05, 6.92475264e-05,\n       6.83034626e-05, 6.79466333e-05, 6.70613944e-05, 6.62480240e-05,\n       6.52451163e-05, 6.42044665e-05, 6.37144809e-05, 6.34556663e-05,\n       6.20393830e-05, 6.12882650e-05, 6.03303398e-05, 5.99324618e-05,\n       5.93744867e-05, 5.87326928e-05, 5.86264965e-05, 5.73910695e-05,\n       5.67287235e-05, 5.63819295e-05, 5.56417853e-05, 5.49041820e-05,\n       5.47601560e-05, 5.44760462e-05, 5.33315438e-05, 5.27630655e-05,\n       5.25529176e-05, 5.22035290e-05, 5.18551456e-05, 5.10223147e-05,\n       5.03840545e-05, 4.97568720e-05, 4.90853052e-05, 4.87101174e-05,\n       4.79629203e-05, 4.72130824e-05, 4.66636544e-05, 4.64488437e-05,\n       4.56043867e-05, 4.49130700e-05, 4.37173151e-05, 4.29364467e-05,\n       4.26089029e-05, 4.23938106e-05, 4.21803422e-05, 4.18024359e-05,\n       4.13894461e-05, 4.08486411e-05, 4.02924355e-05, 3.86187846e-05,\n       3.82706979e-05, 3.81456366e-05, 3.78950774e-05, 3.73537213e-05,\n       3.70846019e-05, 3.65945511e-05, 3.57692321e-05, 3.53630659e-05,\n       3.52661447e-05, 3.48770344e-05, 3.45560213e-05, 3.44066632e-05,\n       3.34108224e-05, 3.30231227e-05, 3.22030290e-05, 3.19448850e-05,\n       3.16504108e-05, 3.10182406e-05, 3.04177364e-05, 3.01627696e-05,\n       2.99111017e-05, 2.92385746e-05, 2.88693629e-05, 2.85217986e-05,\n       2.80745479e-05, 2.79378956e-05, 2.75545726e-05, 2.69615947e-05,\n       2.57845561e-05, 2.53109384e-05, 2.51727700e-05, 2.48427918e-05,\n       2.47189340e-05, 2.44004698e-05, 2.43443149e-05, 2.42643882e-05,\n       2.37390455e-05, 2.33699596e-05, 2.32399019e-05, 2.25693846e-05,\n       2.23750078e-05, 2.21332109e-05, 2.14582629e-05, 2.13064720e-05,\n       2.10777053e-05, 2.08614687e-05, 2.03858092e-05, 2.00935040e-05,\n       1.98781182e-05, 1.96337682e-05, 1.95270389e-05, 1.89794598e-05,\n       1.84664701e-05, 1.81960804e-05, 1.81166579e-05, 1.79686144e-05,\n       1.76057159e-05, 1.74397397e-05, 1.63930547e-05, 1.61938325e-05,\n       1.61299669e-05, 1.59346675e-05, 1.55608835e-05, 1.52792099e-05,\n       1.51769218e-05, 1.50019310e-05, 1.47703087e-05, 1.45910205e-05,\n       1.43748563e-05, 1.41837426e-05, 1.39834724e-05, 1.38038734e-05,\n       1.36965198e-05, 1.34227281e-05, 1.31909771e-05, 1.26165655e-05,\n       1.24016692e-05, 1.22123587e-05, 1.20618867e-05, 1.19400891e-05,\n       1.18050231e-05, 1.17425104e-05, 1.13987993e-05, 1.13345764e-05,\n       1.12711962e-05, 1.10335099e-05, 1.09635919e-05, 1.06111087e-05,\n       1.05968974e-05, 1.02542782e-05, 1.01070989e-05, 9.58873350e-06,\n       9.38686195e-06, 9.33113291e-06, 9.30084969e-06, 8.89587620e-06,\n       8.85434147e-06, 8.63994550e-06, 8.22465873e-06, 7.98184457e-06,\n       7.88002558e-06, 7.75737346e-06, 7.70556468e-06, 7.61513945e-06,\n       7.57523327e-06, 7.40639138e-06, 7.36345849e-06, 7.16658003e-06,\n       7.03763712e-06, 6.92858826e-06, 6.75361719e-06, 6.73739625e-06,\n       6.61181279e-06, 6.51347325e-06, 6.26744294e-06, 5.95615415e-06,\n       5.77664427e-06, 5.71363730e-06, 5.62163826e-06, 5.39542804e-06,\n       5.35628711e-06, 5.23239075e-06, 5.11704116e-06, 5.08260589e-06,\n       5.04032708e-06, 4.93110175e-06, 4.84766351e-06, 4.72183017e-06,\n       4.67923604e-06, 4.62580213e-06, 4.27165242e-06, 4.24808254e-06,\n       4.13130635e-06, 4.05899875e-06, 3.97895515e-06, 3.95052722e-06,\n       3.87507447e-06, 3.37386457e-06, 3.32745342e-06, 3.27610240e-06,\n       3.24765833e-06, 3.22905429e-06, 3.19692562e-06, 3.12458172e-06,\n       3.08123684e-06, 3.05307005e-06, 3.03719086e-06, 2.98563310e-06,\n       2.88154112e-06, 2.69672305e-06, 2.62381772e-06, 2.45352474e-06,\n       2.42290458e-06, 2.36336424e-06, 2.30016948e-06, 2.28132406e-06,\n       2.26840974e-06, 2.24411615e-06, 2.22611018e-06, 2.14853163e-06,\n       2.12825113e-06, 2.11197978e-06, 1.98656029e-06, 1.97189593e-06,\n       1.96782409e-06, 1.95734096e-06, 1.90216936e-06, 1.81273351e-06,\n       1.80242417e-06, 1.78243665e-06, 1.73929343e-06, 1.70179565e-06,\n       1.68184407e-06, 1.67071625e-06, 1.50243643e-06, 1.43701061e-06,\n       1.42825660e-06, 1.40513942e-06, 1.39635046e-06, 1.38401626e-06,\n       1.32635520e-06, 1.28331833e-06, 1.26841116e-06, 1.26223381e-06,\n       1.23371186e-06, 1.22516293e-06, 1.20368297e-06, 1.18515125e-06,\n       1.17270800e-06, 1.13309304e-06, 1.12095771e-06, 1.08633375e-06,\n       1.05276763e-06, 1.01467520e-06, 1.01016603e-06, 1.00467042e-06,\n       9.91762966e-07, 9.64489031e-07, 9.31092150e-07, 9.18589804e-07,\n       8.80022863e-07, 8.62944258e-07, 8.31088275e-07, 8.20019633e-07,\n       8.07343949e-07, 8.03053741e-07, 7.95301798e-07, 7.31134121e-07,\n       7.19911960e-07, 6.83019034e-07, 6.76391402e-07, 6.74391866e-07,\n       6.56006509e-07, 6.54387012e-07, 6.40993934e-07, 6.31842802e-07,\n       6.28417285e-07, 6.18559558e-07, 6.16108263e-07, 5.91210255e-07,\n       5.85662699e-07, 5.79753866e-07, 5.60121964e-07, 5.46881907e-07,\n       5.44532404e-07, 5.25333751e-07, 5.23499284e-07, 5.10977189e-07,\n       4.39732824e-07, 4.33633682e-07, 4.16276970e-07, 4.14359846e-07,\n       4.08293287e-07, 4.02551215e-07, 3.97935106e-07, 3.71005051e-07,\n       3.64965915e-07, 3.60966398e-07, 3.41720426e-07, 3.21171977e-07,\n       3.15329883e-07, 3.14821535e-07, 3.11297871e-07, 3.10417360e-07,\n       2.97815105e-07, 2.89608503e-07, 2.82997493e-07, 2.74600000e-07,\n       2.67755422e-07, 2.27296253e-07, 2.23748298e-07, 2.23514814e-07,\n       2.19437152e-07, 2.15366594e-07, 2.03151415e-07, 2.00835628e-07,\n       1.65902002e-07, 1.63565304e-07, 1.55702633e-07, 1.45936443e-07,\n       1.28528219e-07, 1.21679147e-07, 1.20913222e-07, 1.08081860e-07,\n       1.05758790e-07, 9.10701554e-08, 8.86433065e-08, 8.43648503e-08,\n       6.23095963e-08, 5.47286687e-08, 4.64174808e-08, 1.92629704e-08,\n       1.15768399e-08, 4.51091373e-09, 2.39344810e-09, 2.15723733e-09,\n       1.91559307e-32, 1.07002173e-32, 8.55872254e-33, 7.59208096e-33,\n       5.43691074e-33, 3.67533072e-33, 3.05085519e-33, 2.79024749e-33,\n       2.44100891e-33, 2.10644631e-33, 1.56663586e-33, 1.25862495e-33,\n       1.25623475e-33, 1.22663657e-33, 9.63793673e-34, 7.44125545e-34,\n       5.59785899e-34, 4.03586585e-34, 3.84523161e-34, 3.49734505e-34,\n       3.49734505e-34, 3.49734505e-34, 3.49734505e-34, 3.49734505e-34,\n       3.49734505e-34, 3.49734505e-34, 3.49734505e-34, 3.49734505e-34,\n       3.49734505e-34, 3.49734505e-34, 3.49734505e-34, 3.49734505e-34,\n       3.49734505e-34, 3.49734505e-34, 3.49734505e-34, 3.49734505e-34,\n       3.49734505e-34, 3.49734505e-34, 3.49734505e-34, 3.49734505e-34,\n       3.49734505e-34, 3.49734505e-34, 3.49734505e-34, 3.49734505e-34,\n       3.49734505e-34, 3.49734505e-34, 3.49734505e-34, 3.49734505e-34,\n       3.49734505e-34, 3.49734505e-34, 3.49734505e-34, 3.49734505e-34,\n       3.49734505e-34, 3.49734505e-34, 3.49734505e-34, 3.49734505e-34,\n       3.49734505e-34, 3.49734505e-34, 3.49734505e-34, 3.49734505e-34,\n       3.49734505e-34, 3.49734505e-34, 3.49734505e-34, 3.49734505e-34,\n       3.49734505e-34, 3.43500876e-34, 2.41231319e-34, 1.90227150e-34,\n       1.43447891e-34, 1.26909138e-34, 4.97901602e-35, 1.10390442e-35])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca = PCA(n_components=784)\n",
    "\n",
    "pca_train = pca.fit_transform(train_X_scale)\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8004dd2ca81b307a375e3f69a494d9a4dd61b0765d451c5fdea3c5a249707c61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}